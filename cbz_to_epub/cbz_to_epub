#!/usr/bin/env python3
#!/Users/richardtodd/venv/cli/bin/python

import concurrent.futures
import os
import sys
import subprocess
import re
from pathlib import Path
from typing import Any
import argparse
from rwt.epub import EpubWriter

# --- Configuration ---
WEBP_QUALITY = '80%'
TEMP_OUT = 'temp_out'

def process_image(jpg_path: Path) -> tuple[str, tuple[int,int], bytes]:
    """
    Converts a JPG to WEBP in memory, compares their sizes, and returns the
    smaller data with its corresponding new filename.

    Args:
        jpg_path: The path to the input JPG file.

    Returns:
        A tuple containing the determined filename (e.g., 'image.webp' or
        'image.jpg') and the image data in bytes.
    """
    original_filename_stem = jpg_path.stem
    jpg_data = jpg_path.read_bytes()

    try:
        # Execute the ImageMagick commands
        result = subprocess.run(
            [ 'magick', 'identify', '-format', '%w %h', 'jpg:-' ],
            input=jpg_data,
            capture_output=True,
            check=True  # Will raise CalledProcessError on failure
        )
        imwidth, imheight = [int(num) for num in result.stdout.split()]

        result = subprocess.run(
            [ 'magick', 'convert', '-quality', WEBP_QUALITY, 'jpg:-',  'webp:-' ],
            input=jpg_data,
            capture_output=True,
            check=True  # Will raise CalledProcessError on failure
        )
        webp_data = result.stdout

        # Compare the original JPG size with the new WEBP size
        if len(webp_data) > 0 and len(webp_data) < len(jpg_data):
            # The WEBP is smaller, so we'll use it
            return f"{original_filename_stem}.webp", (imwidth,imheight), webp_data
        else:
            # The JPG is smaller or conversion failed, use the original
            return f"{original_filename_stem}.jpg", (imwidth,imheight), jpg_data
            
    except subprocess.CalledProcessError as e:
        # This error occurs if ImageMagick fails to convert the image
        print(f"⚠️  Could not convert '{jpg_path.name}'. Using original JPG. Reason: {e.stderr.decode().strip()}", file=sys.stderr)
        return f"{original_filename_stem}.jpg", (0,0), jpg_data

def create_optimized_zip(
    source_archive: Path,
    metadata: dict[str,Any],
    output_file: Path
) -> None:
    """
    Finds all JPG images in a source directory, processes them in parallel to
    find the smallest version (JPG vs. WEBP), and adds that version to a
    ZIP archive.

    Args:
        source_directory: Path to the directory containing .jpg images.
        metadata: a dict of metadata about the file
        output_file: Path for the final .zip file.
    """
    nonalph = re.compile(r'[^a-zA-Z0-9.]')
    # 1. expand the comic archive
    src_path = Path(TEMP_OUT)
    try:
        subprocess.run(
            ['7zz', 'e', f'-o{TEMP_OUT}', str(source_archive)],
            check=True
        )
    except (FileNotFoundError, subprocess.CalledProcessError):
        print("❌ Error: could not expand the comic!", file=sys.stderr)
        return

    # 2. Find all .jpg files in the source directory
    jpg_files: list[Path] = list(src_path.glob('*.jpg')) + list(src_path.glob('*.jpeg')) + list(src_path.glob('*.JPG'))
    if not jpg_files:
        print(f"🤷 No .jpg or .jpeg files found in '{src_path}'.", file=sys.stderr)
        return
    jpg_files.sort() # get the first one as the cover image...
    cover_img_file = jpg_files[0]

    max_processes = os.cpu_count() or 4     
    print(f"⚙️  Found {len(jpg_files)} images. Starting processing with up to {max_processes} parallel workers.")

    # 3. Process files in parallel and write to the zip archive
    try:
        with EpubWriter(str(output_file), metadata['title'], metadata['author'], metadata['year']) as ew:
            image_files : list[str] = []
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_processes) as executor:
                # Create a future for each image processing task
                future_to_path = {
                    executor.submit(process_image, jpg_path): jpg_path for jpg_path in jpg_files
                }

                # Process results as they are completed
                for future in concurrent.futures.as_completed(future_to_path):
                    original_path = future_to_path[future]
                    try:
                        filename, dims, data = future.result()
                        if filename.startswith('zzz'):
                            print('Skipping',filename,file=sys.stderr)
                        else:
                            allalpha = nonalph.sub('',filename)  # only alphanumerics
                            ew.add_image_content(allalpha, data, original_path==cover_img_file, dims)
                            image_files.append(allalpha)
                    except Exception as exc:
                        print(f"❌ Failed to process '{original_path.name}': {exc}", file=sys.stderr)

            # ok, now write xhtml files for all the images, in order...
            image_files.sort()
            for ifile in image_files:
                ew.add_fullpage_pic(str(Path(ifile).with_suffix('.xhtml')), ifile)

            # add the two TOC entries
            ew.add_toc_link(str(Path(image_files[0]).with_suffix('.xhtml')), 'Cover')
            ew.add_toc_link(str(Path(image_files[-1]).with_suffix('.xhtml')), 'Last Page')

        print(f"\n🎉 Success! Created optimized archive at: {output_file}")

    except Exception as exc:
        print(f"An unexpected error occurred: {exc}", file=sys.stderr)
        import traceback
        traceback.print_exception(exc)

def prepare_out_dir(odir: Path) -> None:
    """Empty the out dir, or create it if necessary"""
    if odir.exists():
        for file in odir.iterdir():
            if file.is_file():  # Check if it's a file
                file.unlink()  # Remove the file
    else:
        odir.mkdir()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Convert a .cbz/.cbr file to .epub')
    parser.add_argument('comic', type=Path, help='The comic to convert')
    parser.add_argument('--series', default='G.I. Joe', help='The name of comic series')
    parser.add_argument('--publisher', default='Marvel', help='the publisher of the comic')
    parser.add_argument('--inum', type=int, default=-1, help='The issue number')
    parser.add_argument('--iyear', type=int, default=-1, help='The issue year of publication')
    args = parser.parse_args()

    odir = Path('temp_out')
    prepare_out_dir(odir)
    title = f'{args.series} {args.inum:03d}'
    result_epub = Path(f'{title}.epub')
    if result_epub.exists():
        print('outfile already exists!', file=sys.stderr)
    else:
        metadata = { 'title': title, 'year': args.iyear, 'author': args.publisher }
        create_optimized_zip(args.comic, metadata, result_epub)
